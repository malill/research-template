├── README.md           <- The top-level README for developers.
├── conf                <- Space for credentials
│
├── data
│   ├── 01_raw          <- Immutable input data
│   ├── 02_intermediate <- Cleaned version of raw (no missing values, outliers, unreadable data etc.)
│   ├── 03_processed    <- Train data used to develop models (including interactions, new features etc. with 2 columns
│   │                     (_a, _b) whenever there are transformations using datapoint's label as part of features),
│   │                     derived test data for prediction (using processed train data and _b columns when applicable)
│   ├── 04_models       <- Trained models (.pkl files using joblib). Naming convention is date YYYYMMDD (for ordering),
│   │                      '_', score, '_' and a short description of the used model
│   ├── 05_model_output <- Model output
│   └── 06_reporting    <- Reports and input to frontend
│
├── docs                <- Space for documentation
│
├── notebooks           <- Jupyter notebooks. Naming convention is date YYYYMMDD (for ordering), '_'
│   │                      and 3 capital letters for kind of notebook.
│   ├── 01_exploration  <- Get the data and explore given and potential features (data: raw)
│   ├── 02_processing   <- Prepare data for modeling (data: raw -> intermediate -> processed)
│   ├── 03_analysis     <- Run many different models and measure performance, significant features, errors, rerun
│   │                     models with subset feature selection (data: processed)
│   ├── 04_tuning       <- Fine tune your model (data: processed)
│   ├── 05_preparation  <- Prepare your test data (data: processed)
│   ├── 06_reports      <- List your results
│
├── references          <- Data dictionaries, manuals, etc.
│
├── results             <- Final analysis docs.
│   ├── figures         <- Generated graphics and figures to be used in reporting
│   ├── submissions     <- Final submission files (.csv). Naming convention is date YYYYMMDD (for ordering), '_',
│                          score, '_' and a short description of the used model (analogue data/04_models)
│
├── requirements.txt    <- The requirements file for reproducing the
|                         analysis environment.
│
├── structure.txt       <- Shows project structure
│
├── .gitignore          <- Avoids uploading data, credentials,
|                         outputs, system files etc
│
└── src                       <- Source code for use in this project.
    ├── __init__.py           <- Makes src a Python module
    │
    ├── d00_utils             <- Functions used across the project
    │   └── remove_accents.py
    │
    ├── d01_data              <- Scripts for reading and writing data etc
    │   └── load_data.py
    │
    ├── d02_intermediate      <- Scripts to transform data from raw to intermediate. CAUTION: some transformations
    │   │                        need processors from d03 (e.g. create a new feature used for filling NAs)
    │   └── create_int_payment_data.py
    │
    ├── d03_processing        <- Transformer classes to turn intermediate data into
    |   |                       modelling input (classes transform method add _a/_b columns when applicable)
    │   └── create_master_table.py
    │
    ├── d04_modelling         <- Scripts to train models and then use trained models to make predictions.
    │   └── train_model.py
    │
    ├── d05_model_evaluation  <- Scripts that analyse model performance and model selection.
    │   └── calculate_performance_metrics.py
    │
    ├── d06_analysis          <- Scripts to analyze results and run custom code for further analysis.
    │   │                        Naming convention is date YYYYMMDD (for ordering)
    │   └── 20200623_analysis.py
    │
    ├── d07_reporting         <- Scripts to produce reporting tables
    │   └── create_rpt_payment_summary.py
    │
    └── d08_visualisation     <- Scripts to create frequently used plots
        └── visualise_patient_journey.py
